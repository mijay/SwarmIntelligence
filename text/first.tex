\chapter{Теоретические основы}\label{sec:first}
\section{Понятия искусственного и вычислительного интеллекта}
Под искусственным интеллектом  понимается довольно обширный класс инструментов и технологий, границы которого во многом определяются историческими либо практическими причинами, а не общепринятыми формальными критериями, которых на данный момент не существует.

Наиболее распространенным подходом к определению интеллектуальности, а, следовательно, и ИИ \nomenclature{ИИ}{Искусственный Интеллект}, является агент-ориентированный подход, изложенный в одной из основополагающих работ в области --- \cite{Russel}. Ключевое понятие для этого подхода --- агент. Это некоторая сущность, которая способна воспринимать окружающую среду посредством датчиков и влиять на нее посредством исполнительных механизмов. Поведение агента считается интеллектуальным, если оно рационально в т.ч. и при меняющихся условиях среды. Эта модель требует наличия свойства адаптивности у алгоритмов ИИ.

Тем не менее, существуют другие подходы, например логический \cite{McCathy} или основанный на поиске \cite{NilsonNJ}, ярким примером которого является алгоритм A-star \cite{AStar}, который в настоящее время не относится к интеллектуальным.

В своей работе я исследовал лишь методы, относящиеся к области вычислительного интеллекта \cite{CompIntel}, интеллектуальность которых общепризнанна. Однако, также как и для интеллекта искусственного, для вычислительного не было построено четкого определения. Обширный обзор разработанных определений можно найти в \cite{CompIntelDef}. В этой-же работе автор приводит собственное, пожалуй, лучшее из представленных в литературе, хотя и излишне общее определение ВИ\nomenclature{ВИ}{Вычислительный Интеллект}: <<Вычислительный интеллект --- это область компьютерных наук, изучающая решение задач, для которых не существует эффективного алгоритмического решения>>.

Во многих работах, например \cite{MultTechDef}, ВИ определяется, как совокупность  различных технологий. Подобный остенсивный \cite{Ostensive} способ определения понятия обладает очевидными недостатками, поскольку не указывает на общие свойства этих технологий и не является расширяемым. В частности, в книге \cite{CompIntel} авторы относят к ВИ 4 типа алгоритмов, а 2 года спустя в \cite{MultTechDef} --- уже 7. Работы, использующие для определения ВИ именно такой --- остенсивный --- подход, обычно содержат довольно подробную классификацию существующих методов.

Согласно этим классификациям алгоритмы ВИ разбиваются на три подкласса: нейронные сети \cite{NS}, нечеткое управление \cite{FS} и эволюционное моделирование \cite{EM}.

\section{Алгоритмы эволюционного моделирования}
Перейдем к более подробному рассмотрению третьего класса алгоритмов --- алгоритмов эволюционного моделирования\nomenclature{АЭМ}{Алгоритмы Эволюционного Моделирования}. Эти алгоритмы предназначены для решения задач комбинаторной оптимизации.

Исторически, первыми представителями этого класса были генетические алгоритмы\nomenclature{ГА}{Генетические Алгоритмы}, предложенные Лоуренсом Фогелем в работе \cite{GA}. В их основу положен принцип моделирования генетической эволюции в смысле синтетической теории эволюции \cite{STE}. В самом общем виде генетический алгоритм формулируется следующим образом:

\begin{enumerate}
    \item Алгоритм оперирует особями --- некоторым представлением решений задачи. Каждая особь однозначно определяет допустимое решение. Для каждой особи определена ее функция приспособленности --- характеристика оптимальности решения ею определяемого.
    \item Алгоритм поддерживает пул особей, называемый популяцией, который характеризует его текущее состояние.
    \item При инициализации алгоритма некоторым образом создается начальная популяция.
    \item На каждом шаге алгоритма производятся три процесса:
    \begin{enumerate}
        \item Мутация: некоторым случайным образом выбираются несколько особей и для каждой из них в популяцию добавляется особь (или несколько особей), которая является ее некоторой случайной модификацией.
        \item Скрещивание: некоторым случайным (либо нет) образом выбираются пары особей.
        \item Для каждой пары некоторым случайным способом создаются и затем добавляются в популяцию некоторое количество особей являющихся производными от данной пары.
        \item Отбор: из популяции удаляются особи имеющие плохую функцию приспособления либо слишком продолжительное время жизни (возможно сочетание критериев).
    \end{enumerate}
    \item Шаг алгоритма повторяется до тех пор пока не выполняться определенные условия. Например, пока в популяции не перестанут происходить существенные изменения.
    \item Результат работы алгоритма --- особь с лучшей функцией приспособленности.
\end{enumerate}

Генетические алгоритмы являются крайне общими методами, обладающими огромным числом параметров, существенно влияющими на их поведение. Для ГА известны способы доказательства корректности и сходимости алгоритмов \cite{ShodGA}, а также определения их эффективности \cite{OptGA}.

Другим АЭМ, зачастую противопоставляемым генетическим, является алгоритм Learnable Evolution Model \nomenclature{LEM}{Learnable Evolution Model}\cite{LEM}. Он также работает с представлением решений в виде особей с определенной функцией приспособленности и представлением текущего состояния в виде популяции. Однако в его основе лежит другая теория эволюции --- теория направленной эволюции (номогенез) \cite{Nomogen}. В самом общем виде алгоритм формулируется так:

\begin{enumerate}
    \item Некоторым способом создается начальная популяция.
    \item На каждом шаге алгоритма выполняются следующие действия:
    \begin{enumerate}
        \item Из популяции выделяются две группы особей: <<хорошие>> и <<плохие>> --- особи соответственно с высоким и низким значением функции приспособленности.
        \item С помощью методов машинного обучения строятся гипотезы --- описания отличительных черт <<хороших>> особей, которые не наблюдаются у <<плохих>>. Возможно также построение обратных гипотез --- черт присутствующих у <<плохих>>, но не у <<хороших>> особей.
        \item Генерируются новые особи, которые удовлетворяют гипотезам и не удовлетворяют обратным гипотезам.
        \item Эти особи тем или иным способом добавляются в популяцию. Например заменяя всех особей не являющихся <<хорошими>>.
    \end{enumerate}
    \item Шаг алгоритма повторяется до тех пор пока не выполняются определенные условия.
    \item Результат  работы алгоритма --- особь с лучшей функцией приспособленности.
\end{enumerate}

Алгоритм Particle Swarm Optimization \nomenclature{PSO}{Particle Swarm Optimization} \cite{PSO} может  служить примером абсолютно другого подхода к АЭМ. В нем, как и в предыдущих алгоритмах, работа ведется с агентами (в английской литературе: particle --- частица), популяцией (в англ. литературе: particle swarm --- рой частиц) и метрикой неоптимальности решения ($f$). Однако, требуется, чтобы агент был представлен вектором в n-мерном пространстве,  причем каждый вектор этого пространства является допустимым решением и, следовательно, потенциальным агентом.

\begin{enumerate}
    \item Для каждого агента $i \in [1,S]$ (где $S$ --- количество агентов) в момент времени $t=T$ определены векторы: $x_i(T)$ --- его координата; $v_i(T)$ --- его скорость; $x^{\sharp}_i(T)$ --- координата наилучшей достигнутой позиции, т.е. $ x^{\sharp}_i(T) = \arg \min \limits_{t \le T} f(x_i(t)) $.
    \item Для всей популяции в момент времени $t=T$ определен вектор наилучшего достигнутого решения $x^*(T) = \arg \min \limits_{i \in [1,S]} f(x^*_i)$.
    \item Некоторым способом задается начальная популяция.
    \item На каждом шаге алгоритма для каждой особи $i$ выполняются следующие действия:
    \begin{enumerate}
        \item Вычисляется новый вектор скорости: $$ v_{ij}(t+1) = wv_{ij}(t) + c_1 r_1 (x^{\sharp}_{ij}(t) - x_{ij}(t)) + c_2 r_2 (x^*_j(t) - x_{ij}(t)) $$ где $w,\, c_1,\, c_2$ --- параметры алгоритма, а $r_1,\, r_2$ --- случайные, равномерно распределенные на $[0;1]$ числа генерируемые независимо для каждого агента.
        \item Вычисляется новая координата агента: $ x_i(t+1) = x_i(t) + v_i(t+1) $ и его метрика $f(x_i(t+1))$.
        \item Определяется $x^{\sharp}_i(t+1)$ и если необходимо обновляется значение $x^*(t+1)$.
    \end{enumerate}
    \item Шаг алгоритма повторяется до тех пор  пока не выполняются определенные условия.
    \item Результат работы алгоритма --- особь с координатой $x^*(t_{\max})$.
\end{enumerate}
 
На основании вышеперечисленных алгоритмов можно выделить общие черты, присущие всем АЭМ:

\begin{enumerate}
    \item \label{EMcommon1} Состояние алгоритма представлено некоторым множеством (популяцией) некоторых объектов (особь). Каждая особь определяет решение, для которых вводится мера оптимальности. Эта мера может быть перенесена на особи (что определяет функцию приспособленности особи).
    \item Алгоритм итеративный. Цель каждой итерации --- увеличить максимальное значение функции приспособленности для особей из популяции. По сути --- провести эволюцию популяции.
    \item Начальное состояние популяции дается алгоритму извне --- обычно генерируется случайно.
    \item \label{EMcommon4} На каждой итерации алгоритм многократно (например для каждой особи, либо фиксированное число раз) выполняет некоторые действия.  Причем действия эти независимые и распараллеливаемые. В некоторых алгоритмах также выделяются стадии пред- и пост-процессинга.
    \item Алгоритм стохастический.
\end{enumerate}
    
Особо отмечу, что вышеприведенные алгоритмы формируют более слабые ограничения для пунктов (\ref{EMcommon1}) и (\ref{EMcommon4}). Основываясь лишь на них, мы можем сформулировать эти пункты как: <<Состояние алгоритма представлено множеством (популяцией) его допустимых решений (особь)>> и <<На каждой итерации алгоритм выполняет некоторые действия для каждой особи>>. Однако существуют примеры АЭМ, которые не вписываются в эти, более узкие, рамки. Например, расширение пункта (\ref{EMcommon1}) необходимо для включения в класс АЭМ алгоритмов муравейника \cite{AntAlg}, а пункта (\ref{EMcommon4}) --- для включения алгоритма гармонического поиска \cite{HarmonySearch}.

Перечисленные свойства не являются обязательными для АЭМ, поскольку этот класс сформировался не вокруг общих свойств, а вокруг общего происхождения и круга решаемых задач, однако, они наблюдаются у всех общеизвестных алгоритмов.

Стоит заметить, что эти свойства являются весьма существенными с точки зрения программных реализаций алгоритмов. Они определяют задачи, которые должны быть решены в каждой из них. Это, в первую очередь, задачи создания удобной программной абстракции, выполнения сервисных операций с популяцией, распараллеливания и распределения по данным вычислений на каждой итерации. Их решение довольно трудоемко, что приводит к мысли о создании специализированных библиотек поддержки. Однако, ввиду чрезмерной общности данных свойств и их неестественности, такие библиотеки будут недостаточно удобны в использовании, хотя их примеры существуют: EO Evolutionary Computation Frameworki \cite{EOECF}, ECF \cite{ECF} и другие.

Неестественность общих свойств АЭМ во многом объясняется тем, что данный класс состоит из двух подклассов, представители которых существенно различны. Это подклассы алгоритмов эволюционных вычислений \cite{EvolComp} и коллективного разума \cite{SwarmIntel}. У каждого из них имеется гораздо больше общих свойств, и эти свойства гораздо естественнее, благодаря чему создание библиотеки поддержки становится более целесообразным.

В своей работе я сфокусировался на разработке подобной библиотеки для класса алгоритмов коллективного разума.

\section{Алгоритмы коллективного разума}
\nomenclature{АКР}{Алгоритмы Коллективного Разума}
Родоначальником этого класса являются уже упомянутый выше алгоритм муравейника (англ. Ant Colony Optimisation\nomenclature{ACO}{Ant Colony Optimisation}) \cite{AntAlg}.  Это алгоритм является более общим, нежели другие приведенные мною ранее алгоритмы, в т.ч. алгоритм PSO, который также как и алгоритм муравейника относится к АКР.  Фактически, он лишь определяет общие принципы построения  аналогичных алгоритмов. Эти принципы были скопированы его разработчиками с принципов поведения колонии муравьев.

Алгоритм работает на графах. В его основе лежит использование множества независимых агентов (здесь и далее <<агент>> --- синоним <<особи>> в терминологии принятой для АКР) --- <<муравьев>>, каждому из которых соответствует решение, итеративно строимое им (муравей перемещается по вершинам графа; его маршрут --- решение). Ключевая особенность алгоритма муравейника в использовании <<феромонов>> ($\tau_{i,j}(t)$) --- разновидности памяти, позволяющей ассоциировать с ребрами графа значения, указывающие на историю его использования муравьями. Кроме того, алгоритм использует эвристику $\eta_{i,j}(t)$.

На каждой итерации алгоритма муравейника для каждого муравья $\mathrm{ant}_k$, $k \in \{1\dotsc n\}$  расположенного  в вершине $i$ производятся следующие действия:

\begin{enumerate}
    \item Вычисляется вероятность перехода муравья в каждую из допустимых вершин. Общая формула: $$ \forall  j \in N:\: p_{i,j}^k(t)=\frac{\left(\tau_{i,j}(t)\right)^\alpha \left(\eta_{i,j}(t)\right)^\beta} {\sum \limits_{l \in N} \left(\tau_{i,l}(t)\right)^\alpha \left(\eta_{i,l}(t)\right)^\beta} $$
    \item Выполняется случайный переход муравья по ребру $(i,\,j)$.
    \item Фиксированным для алгоритма способом определяется функция $\Delta\tau_{i,j}^k(t)$ и $\forall l \ne j \mbox{ полагаем } \Delta\tau_{i,l}^k(t) = 0$
\end{enumerate}
    
Кроме того, на каждой итерации, для всех ребер осуществляется пересчет соответствующих феромонов: $$\tau_{i,j}(t+1) = \rho\tau_{i,j}(t) + \sum_{k=1}^n \Delta\tau_{i,j}^k(t),\,\mbox{где }0 \le \rho < 1$$

Алгоритм первоначально был сформулирован для решения задачи коммивояжёра \cite{Barasin}, однако благодаря своей обобщенности и наличию параметров был адаптирован для решения многих других задач, примеры которых можно найти в \cite{SwarmIntelDM}.

\section{Многоагентные алгоритмы}
Алгоритм муравейника является не только характерным примером АКР, но и другого, чрезвычайно похожего на первый взгляд, класса алгоритмов --- многоагентных алгоритмов\nomenclature{МАА}{Многоагентные Алгоритмы}. Границу между этими двумя классами не проводят в большей части литературы.

Дело в том, что МАА и АКР оба базируются на агентах, однако трактуют это понятие по разному. Как уже было указано выше, для АКР агент --- то же самое, что и особь для АЭМ, т.е. сущность, которой он оперирует и которая представляет решение. В то время как в МАА под агентом подразумевается агент в терминах агент-ориентированного подхода к ИИ \cite{Russel}, т.е. независимая, решающая задачу сущность, воспринимающая окружающую среду и взаимодействующая с ней.

Поскольку сам МАА также является агентом в этих терминах, то естественно, что необходимо вводить специальные ограничения, делающие задачи решаемые агентами разных уровней (МАА в целом $\longleftrightarrow$ агент в МАА) существенно различными. Типичным ограничением является  возможность работы лишь в подмножестве пространства исходной задачи.

Из определений очевидно, что МАА являются подмножеством АКР: с точностью до формулировок МАА являются АКР, в котором каждый агент решает задачу независимо от других (он может либо игнорировать другие  агенты, либо взаимодействовать с ними лишь опосредованно --- через сообщения или разделяемую память). Но это означает, что многоагентные системы, которые по сути являются МАА, естественно сводятся к терминам АКР. Этот факт с практической точки зрения представляет большой интерес.

К многоагентным системам относятся, в частности, эмуляции жизни, эволюции, социума и т.п., некоторые игры и многое другое. Все эти системы могут интерпретироваться как алгоритмы АКР и реализовываться поверх библиотеки их поддержки, что существенно расширяет область применимости такой библиотеки.

Примером АКР, которые не является МАА, может служить алгоритм гравитационного поиска (англ. Gravitational Search Algorithm \nomenclature{GSA}{Gravitational Search Algorithm}) \cite{GraviSearch}. Агентами в этом алгоритме  обладают координатой $X_i(t)$ в пространстве решений, скоростью перемещения в этом пространстве --- $V_i(t)$ и массой (авторы предлагают использовать три вида масс: инерционную $M_{ii}(t)$, активную $M_{ai}(t)$ и пассивную $M_{pi}(t)$ гравитационные, однако способы обновления и вычисления их приводят только для ситуации, когда $M_i(t)=M_{ai}(t)=M_{pi}(t)=M_{ii}(t)$). Для агента определена его оценка --- функция качества решения им определенного $f_i(t) = f(X_i(t))$.

Тогда алгоритм каждой итерации следующий:

\begin{enumerate}
    \item Вычислить силы взаимодействия для каждой пары объектов. Для $d$ координаты они вычисляются по формуле:
    \begin{gather*}
        F_{ij}(t) = G(t) \frac{M_{pi}(t) M_{aj}(t)}{R_{ij}(t)} \left(x_i^d(t) - x_j^d(t)\right) \\
        \mbox{где } R_{ij}(t) = \left\|X_i(t),\, X_j(t)\right\|_2 \mbox{ --- евклидово расстояние.}
    \end{gather*}
    Это правило является видоизмененным законом всемирного тяготения. Отличия заключаются во-первых в том, что множитель $R_{ij}(t)$ имеет степень $-1$, а не $-3$, а во-вторых, в том что гравитационная постоянная $G$ введена как функция от времени. Первый изменение было выведено авторами экспериментально --- так алгоритм быстрее сходился. Второе является следствием поисковой природы алгоритма --- для нахождения точных решений необходимо повышать <<аккуратность>> алгоритма со временем, для чего необходимо уменьшить силы взаимодействия.
    \item С помощью независимых случайных величин ${rnd}_i \in [0,\,1]$, вычисляются $F_i(t) = \sum \limits_{j=1,\, j \ne i}^N {rnd}_j F_{ij}(t)$ и $a_i(t) = F_i(t) \left/M_{ii}(t)\right.$. Это, соответственно, правило сложения сил, в которое добавили элемент случайности, и второй закон Ньютона.
    \item Производится перемещение объекта: \begin{align*} V_i(t+1) &= {rand}_i V_i(t) + a_i(t) \\ X_i(t+1) &= X_i(t) + V_i(t+1) \end{align*} где ${rand}_i$ --- независимые случайные величины равномерно распределенные на $[0,\,1]$. Затем пересчитывается его оценка.
    \item Обновляются массы объектов:
    \begin{align*}
        w(t) &= \min_{i\in\{1\dotsc N]} f_i(t) \\
        b(t) &= \max_{i\in\{1\dotsc  N]} f_i(t) \\
        m_i(t) &= \frac{f_i(t) -  w(t)}{b(t)-w(t)} \\
        M_i(t+1) &= \frac{m_i(t)}{\sum_{j=1}^N m_j(t)}
    \end{align*}
\end{enumerate}

На примере трех вышеприведенных алгоритмов можно рассмотреть еще одну важную характеристику АКР --- тип пространства агентов. В части алгоритмов, в т.ч. в PSO и в GSA,  используются агенты располагаемые (обладающие координатой) в пространстве допустимых решений, в то время как в остальных алгоритмах (из приведенных --- в ACO) --- в пространстве задачи. Агенты первого типа являются агентами, оптимизирующими решения. Они аналогичны особям, используемым в ГА, LEM и других эволюционных алгоритмах \cite{EA}. Агенты второго типа являются агентами, строящими решение. Они могут быть использованы только в АКР и, более того, только в MAA. Большинство МАА (в т.ч. многоагентные системы) основаны на них. Однако, существуют исключения: упомянутый выше PSO, Stochastic diffusion search \cite{SDS} и другие.

\section{Общие свойства АКР}\label{sec:akrprop}
\textit{Обобщив вышесказанное, можно представить класс АКР в следующем виде: (картинка АКР --- неМАА + МАА --- МАА со строящими агентами)}

Сформулируем общие свойства АКР:

\begin{enumerate}
    \item Алгоритм работает в некотором пространстве с координатами (карта).
    \item Работа алгоритма сводится к оперированию множеством (рой) сущностей (агентами) в этом пространстве.
    \item Состояние алгоритма определяется состоянием роя. Реже также используется память ассоциированная с точками пространства и/или небольшое количество глобальных переменных.
    \item Алгоритм итеративный. Одну итерацию будем называть ходом.
    \item \label{akrprop:indep} В течении хода алгоритм производит независимые действия над каждым агентом роя (обработка). Эти действия не образуют сторонних эффектов друг на друга: т.е. результат обработки для каждого агента не зависит от того, были ли обработаны другие агенты, в каком порядке они были обработаны, как они изменились и изменили хранимые данные в ходе обработки.
    \item Условие остановки алгоритмом не специфицируется.
    \item Начальное состояние данных и роя дается алгоритму извне. Координаты агентов в начальном рое обычно случайны (реже при их генерации используется эвристика).
    \item Алгоритм стохастический. Генерация случайных чисел (обычно многократная) необходима при обработке каждого агента.
\end{enumerate}
    
МАА в дополнение к вышеперечисленным также обладает следующими свойствами:

\begin{enumerate}
    \item Его агенты независимы. Результат обработки любого агента не зависит от состояния других агентов в любой момент времени. Взаимодействие агентов может быть лишь опосредованным, например, через совместный доступ к памяти.
    \item Агенты могут действовать лишь в своей ограниченной окрестности.
\end{enumerate}

АКР с оптимизирующими агентами обладает лишь одним специфичным свойством: карта является пространством допустимых решений, таким образом каждому агенту соответствует решение. Меру оптимальности (или отношение <<быть оптимальнее>>) определенную на решениях можно распространить на агентов и затем использовать для их сравнения.

В АКР со строящими агентами карта является пространством задачи. Таким образом каждый агент не является полноценным решением, а значит невозможно без введения эвристики производить их сравнение.
