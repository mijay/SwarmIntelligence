\chapter{Теоретические основы}\label{sec:first}
\section{Понятия искусственного и вычислительного интеллекта}
Под искусственным интеллектом  понимается довольно обширный класс инструментов и технологий, границы которого во многом определяются историческими либо практическими причинами, а не общепринятыми формальными критериями, которых на данный момент не существует.

Наиболее распространенным подходом к определению интеллектуальности, а, следовательно, и ИИ \nomenclature{ИИ}{Искусственный Интеллект}, является агент-ориентированный подход, изложенный в одной из основополагающих работ в области~--- \cite{Russel}. Ключевое понятие для этого подхода~--- агент. Это некоторая сущность, которая способна воспринимать окружающую среду посредством датчиков и влиять на нее посредством исполнительных механизмов. Поведение агента считается интеллектуальным, если оно рационально, в том числе и при меняющихся условиях среды. Эта модель требует наличия свойства адаптивности у алгоритмов ИИ.

Тем не менее, существуют другие подходы, например логический \cite{McCathy} или основанный на поиске \cite{NilsonNJ}, ярким примером которого является алгоритм A-star \cite{AStar}, который в настоящее время не относится к интеллектуальным.

В своей работе я исследовал лишь методы, относящиеся к области вычислительного интеллекта \cite{CompIntel}, интеллектуальность которых общепризнана. Однако, также как и для интеллекта искусственного, для вычислительного не было построено четкого определения. Обширный обзор разработанных определений можно найти в \cite{CompIntelDef}. В этой же работе автор приводит собственное, пожалуй, лучшее из представленных в литературе, хотя и излишне общее определение ВИ\nomenclature{ВИ}{Вычислительный Интеллект}: <<Вычислительный интеллект~--- это область компьютерных наук, изучающая решение задач, для которых не существует эффективного алгоритмического решения>>.

Во многих работах, например \cite{MultTechDef}, ВИ определяется как совокупность  различных технологий. Подобный остенсивный \cite{Ostensive} способ определения понятия обладает очевидными недостатками, поскольку не указывает на общие свойства этих технологий и не является расширяемым. В частности, в книге \cite{CompIntel} авторы относят к ВИ четыре типа алгоритмов, а 2 года спустя в \cite{MultTechDef}~--- уже семь. Работы, использующие для определения ВИ именно такой~--- остенсивный~--- подход, обычно содержат довольно подробную классификацию существующих методов.

Согласно этим классификациям алгоритмы ВИ разбиваются на три подкласса: нейронные сети \cite{NS}, нечеткое управление \cite{FS} и эволюционное моделирование \cite{EM}.




\section{Алгоритмы эволюционного моделирования}
Перейдем к более подробному рассмотрению третьего класса алгоритмов~--- алгоритмов эволюционного моделирования\nomenclature{АЭМ}{Алгоритмы Эволюционного Моделирования}. Эти алгоритмы предназначены для решения задач комбинаторной оптимизации.

Исторически, первыми представителями этого класса были генетические алгоритмы\nomenclature{ГА}{Генетические Алгоритмы}, предложенные Лоуренсом Фогелем в работе \cite{GA}. В их основу положен принцип моделирования генетической эволюции в смысле синтетической теории эволюции \cite{STE}. В самом общем виде генетический алгоритм формулируется следующим образом:

\begin{enumerate}
    \item Алгоритм оперирует особями~--- некоторым представлением решений задачи. Каждая особь однозначно определяет допустимое решение. Для каждой особи определена ее функция приспособленности~--- характеристика оптимальности решения, ею определяемого.
    \item Алгоритм поддерживает пул особей, называемый популяцией, который характеризует его текущее состояние.
    \item При инициализации алгоритма некоторым образом создается начальная популяция.
    \item На каждом шаге алгоритма производятся три процесса:
    \begin{enumerate}
        \item Мутация: некоторым случайным образом выбираются несколько особей, и для каждой из них в популяцию добавляется особь (или несколько особей), которая является ее некоторой случайной модификацией.
        \item Скрещивание: некоторым случайным (либо нет) образом выбираются пары особей. Для каждой из них некоторым случайным способом создаются и затем добавляются в популяцию некоторое количество производных особей.
        \item Отбор: из популяции удаляются особи, имеющие плохую функцию приспособления либо слишком продолжительное время жизни (возможно сочетание критериев).
    \end{enumerate}
    \item Шаг алгоритма повторяется до тех пор, пока не выполнятся определенные условия. Например, пока в популяции не перестанут происходить существенные изменения.
    \item Результат работы алгоритма~--- особь с лучшей функцией приспособленности.
\end{enumerate}

Для ГА известны способы доказательства корректности и сходимости алгоритмов \cite{ShodGA}, а также определения их эффективности \cite{OptGA}.

Другим АЭМ, зачастую противопоставляемым генетическим, является алгоритм Learnable Evolution Model \nomenclature{LEM}{Learnable Evolution Model} \cite{LEM}. Он также работает с представлением решений в виде особей с определенной функцией приспособленности и представлением текущего состояния в виде популяции. Однако в его основе лежит другая теория эволюции~--- теория направленной эволюции (номогенез) \cite{Nomogen}. В самом общем виде алгоритм формулируется так:

\begin{enumerate}
    \item Некоторым способом создается начальная популяция.
    \item На каждом шаге алгоритма выполняются следующие действия:
    \begin{enumerate}
        \item Из популяции выделяются две группы особей: <<хорошие>> и <<плохие>>~--- особи соответственно с высоким и низким значением функции приспособленности.
        \item С помощью методов машинного обучения строятся гипотезы~--- описания отличительных черт <<хороших>> особей, которые не наблюдаются у <<плохих>>. Возможно также построение обратных гипотез~--- черт присутствующих у <<плохих>>, но не у <<хороших>> особей.
        \item Генерируются новые особи, которые удовлетворяют гипотезам и не удовлетворяют обратным гипотезам.
        \item Эти особи тем или иным способом добавляются в популяцию. Например, заменяя всех особей, не являющихся <<хорошими>>.
    \end{enumerate}
    \item Шаг алгоритма повторяется до тех пор, пока не выполняются определенные условия.
    \item Результат  работы алгоритма~--- особь с лучшей функцией приспособленности.
\end{enumerate}

В качестве примера алгоритма АЭМ, не оперирующего понятием <<эволюция>>, можно привести алгоритм Stochastic Diffusion Search \nomenclature{SDS}{Stochastic Diffusion Search} \cite{SDS}. Он, как и предыдущие алгоритмы, решает задачу поиска оптимального решения (элемента множества $S$) с точки зрения некоторой характеристики ($f: S\to\mathbb{R}$). В нем также вводится понятие особи, однако в SDS особь не отождествляется с решением, а является независимым объектом, которому в каждый момент времени сопоставляют решение, т.о. может рассматриваться как частично определенная функция $a_i: T\to S$, $i\in\{1\dotsc n\}$. Алгоритм формулируется следующим образом:

\begin{enumerate}
    \item Некоторым способом особям сопоставляются начальные решения $a_i(0)$.
    \item На каждом шаге алгоритма выполняются следующие действия:
    \begin{enumerate}
        \item Для всех особей вычисляется качество их текущего решения: $f(a_i(t))$.
        \item Особи разделяются на две группы: <<хорошие>> и <<плохие>>~--- особи соответственно с высоким и низким качеством решения.
        \item Для каждой <<плохой>> особи $i$:
        \begin{enumerate}
            \item Случайно выбирается особь $j\in\{1\dotsc n\}\setminus\{i\}$.
            \item Если особь $j$ <<хорошая>>, то $a_i(t+1)\gets a_j(t)$,
            \item иначе $a_i(t+1)\gets \mathrm{Rand}(S)$.
        \end{enumerate}
        \item Для всех <<хороших>> особей $a_i(t+1)\gets a_i(t)$.
    \end{enumerate}
    \item Шаг алгоритма повторяется до тех пор, пока всем особям не будет сопоставлено малое число (или ровно одно) решений: $$\left\|\bigcup\limits_{i\in\{1\dotsc n\}} \{a_i(t)\}\right\|\to 1$$
    \item Результат работы алгоритма~--- решение, которое сопоставлено наибольшему числу особей.
\end{enumerate}

Более подробный анализ SDS с доказательством некоторых его свойств, включая временную сложность $o(n)$, приведены в \cite{SDSTime}.
 
На основании вышеперечисленных алгоритмов можно выделить общие черты, присущие всем АЭМ:

\begin{enumerate}
    \item Алгоритм решает задачу оптимизации функции (называемой также функцией качества решения, функцией приспособленности) $f:S\to\mathbb{R}$, определенной на множестве значений (называемом также множеством решений) $S$. Чаще всего множество $S$ велико, а функция $f$ является трудно вычислимой.
    \item \label{EMcommon1} Состояние алгоритма представлено некоторым множеством (популяцией) некоторых объектов (особей) и, возможно, производными данными. Состояние алгоритма однозначно определяет набор решений~--- выбранных значений из множества $S$.
    \item Алгоритм итеративный. Цель каждой итерации~--- увеличить максимальное значение функции приспособленности для решений, определенных текущим состоянием. Фактически, провести эволюцию популяции.
    \item Начальное состояние дается алгоритму извне~--- обычно генерируется случайно.
    \item \label{EMcommon4} На каждой итерации алгоритм многократно (например для каждой особи, либо фиксированное число раз) выполняет некоторые действия.  Причем действия эти независимые и замкнутые относительно особей (т.е. состояние особи не может быть изменено дважды в процессе обработки). В некоторых алгоритмах также выделяются стадии пред- и пост-процессинга.
    \item Алгоритм стохастический.
\end{enumerate}
    
Особо отметим, что вышеприведенные алгоритмы формируют более слабые ограничения для пунктов (\ref{EMcommon1}) и (\ref{EMcommon4}). Основываясь лишь на них, мы можем утверждать, что во-первых <<Особь однозначно определяет одно решение>>, и во-вторых, <<На каждой итерации алгоритм выполняет некоторые действия для каждой особи>>. Однако существуют примеры АЭМ, которые не вписываются в эти, более узкие, рамки. Например, расширение пункта (\ref{EMcommon1}) необходимо для включения в класс АЭМ алгоритмов муравейника (англ. Ant Colony Optimisation) \cite{AntAlg} (решение в них кодируется не особью, а производными данными), а пункта (\ref{EMcommon4})~--- для включения алгоритма гармонического поиска \cite{HarmonySearch}.

Перечисленные свойства не являются определяющими для класса АЭМ, однако, они наблюдаются у всех общеизвестных алгоритмов.

Стоит заметить, что эти свойства являются весьма существенными с точки зрения программных реализаций алгоритмов. Они определяют задачи, которые должны быть решены в каждой из них. Это, в первую очередь, задачи создания удобной программной абстракции, выполнения сервисных операций с популяцией, распараллеливания и распределения по данным вычислений на каждой итерации. Их решение довольно трудоемко, что приводит к мысли о создании специализированных библиотек поддержки. Подобные библиотеки существуют (в качестве примера можно привести EO Evolutionary Computation Framework \cite{EOECF} и ECF \cite{ECF}), однако ввиду чрезмерной общности данных свойств и их неестественности, такие библиотеки недостаточно удобны в использовании.

Неестественность общих свойств АЭМ во многом объясняется тем, что данный класс состоит из двух подклассов, представители которых существенно различны. Это подклассы алгоритмов эволюционных вычислений \cite{EvolComp} и коллективного разума \cite{SwarmIntel}. У каждого из них имеется гораздо больше общих свойств, и эти свойства гораздо естественнее, благодаря чему создание библиотеки поддержки становится более целесообразным.

В своей работе я сфокусировался на разработке подобной библиотеки для класса алгоритмов коллективного разума.




\section{Алгоритмы коллективного разума}\label{sec:akr}
Исторически первым представителем класса алгоритмов коллективного разума \nomenclature{АКР}{Алгоритмы Коллективного Разума} (англ. Swarm Intelligence Algorithms) является алгоритм Particle Swarm Optimization \nomenclature{PSO}{Particle Swarm Optimization} \cite{PSO} опубликованый в 1942 г. Однако непосредственно термин АКР, а также ключевые свойства данного класса алгоритмов, впервые были сформулированы только в 1989 г. в статье \cite{SwarmInRobotics}.

Основополагающей работой для всего класса АКР, во многом определившей его вид, считается \cite{AntAlg}. В ней описывается уже упоминавшийся ранее алгоритм муравейника для решения задачи коммивояжёра \cite{Barasin}. Позже, благодаря своей обобщенности, этот алгоритм был адаптирован для решения многих других задач, примеры которых можно найти в \cite{SwarmIntelDM}. Рассмотрим алгоритм муравейника в формулировке для решения задачи поиска кратчайшего пути на графе.

Дан большой взвешенный граф $G$. $\eta_{i,j}$~--- величина, обратная весу ребра $(i,j)$. Необходимо найти кратчайший путь между выделенными вершинами $A$ и $B$.

Алгоритм муравейника, как и другие представители класса АЭМ, оперирует популяцией особей (<<агентов>> в терминологии АКР; <<муравьев>> в терминологии данного алгоритма) и дополнительными данными: <<феромонами>> ($\tau_{i,j}(t)$), позволяющими ассоциировать с ребрами графа $G$ значения, указывающие на историю его использования муравьями. Алгоритм формулируется следующим образом:

\begin{enumerate}
    \item Изначально все муравьи находятся в вершине $A$. Полагаем $\forall (i, j) \in G: \tau_{i, j}(0) = 0$.
    \item На каждом шаге алгоритма для каждого муравья $\mathrm{ant}_k$, $k \in \{1\dotsc n\}$, расположенного в вершине $i$, производятся следующие действия:
    \begin{enumerate}
        \item Вычисляется вероятность перехода муравья в каждую из допустимых вершин. Общая формула: $$ \forall  j \:|\: (i,j)\in G:\: p_{i,j}^k(t)=\frac{\left(\tau_{i,j}(t)\right)^\alpha \left(\eta_{i,j}\right)^\beta} {\sum \limits_{l \in N} \left(\tau_{i,l}(t)\right)^\alpha \left(\eta_{i,l}\right)^\beta} $$
        \item Выполняется случайный переход муравья по ребру $(i,\,j)$.
        \item Ребро $j$ записывается в конец <<пройденного пути>> муравья~--- $L_k$.
    \end{enumerate}
    \item Для всех муравьев $k$, таких что $\mathrm{Last}(L_k)=B$, выполняем:
        \begin{enumerate}
            \item Обновляем уровнь ферромонов на всем пройденом муравьем пути:
                $$
                    \Delta\tau_{i,j}^k=
                        \begin{cases}
                            q\left/\|L_k\|\right.,&\text{если $(i,j)\in L_k$;}\\
                            0,&\text{иначе.}
                        \end{cases}
                $$
                \capt{где $q$~--- константа.}
            \item Переносим муравья в $A$ и сбрасываем пройденный им путь.
        \end{enumerate}
    \item Пересчитываем состояние феромонов:
        $$\tau_{i,j}(t+1) = \rho\tau_{i,j}(t) + \sum_{k=1}^n \Delta\tau_{i,j}^k$$\capt{где $0 \le \rho < 1$~--- константа.}
   \item Шаг алгоритма повторяется до тех пор, пока в графе не образуется путь, помеченный <<высоким уровнем>> феромонов: $\forall (i, j)\in\mathrm{Path}:\tau_{i, j}(t)\ge\Gamma$.
   \item Результат работы алгоритма~--- путь, помеченный высоким уровнем феромонов.
\end{enumerate}

Этот алгоритм был разработан на основании анализа поведения колонии муравьев. Стоит отметить, что подобный натуралистический подход часто применяется при разработке алгоритмов АКР. Например, так были разработаны алгоритм пчелиной колонии (англ. Bee Colony Algorithm) \cite{Bee} и алгоритм светлячка (англ. Firefly Algorithm) \cite{Firefly}. Во многом именно аналогичное происхождение объясняет схожесть свойств алгоритмов АКР.

Однако, было бы неверно утверждать, что все алгоритмы АКР базируются на принципах, почерпнутых из живой природы. Вышеупомянутый PSO причисляется к классу АКР, но, очевидно, являются полностью искуственными. Также существует целый подкласс АКР, базирующихся на принципах неживой природы. Типичным его представителем является алгоритм гравитационного поиска (англ. Gravitational Search Algorithm) \nomenclature{GSA}{Gravitational Search Algorithm} \cite{GraviSearch}. Рассмотрим его подробнее.

Задача алгоритма~--- в пространстве задачи $\mathcal{X}$ найти вектор $X$ с минимальным значением функции $f: \mathcal{X}\to\mathbb{R}$. Агенты в этом алгоритме обладают координатой $X_i(t)\in\mathcal{X}$, скоростью перемещения в пространстве решений~--- $V_i(t)$ и массой~--- $M_i(t)$. Для агента определена его оценка~--- функция качества решения, им определенного $f_i(t) = f(X_i(t))$. Алгоритм формулируется следующим образом:

\begin{enumerate}
    \item Некоторым способом агентам присваиваются начальные координаты $X_i(0)$.
    \item На каждом шаге алгоритма для каждого агента $i \in \{1\dotsc n\}$ выполняются следующие действия:
    \begin{enumerate}
        \item Вычислить силы взаимодействия с каждым другим агентом $j: j \ne i$ по формуле:
            $$F_{ij}(t) = G(t) \frac{M_i(t) M_j(t)}{R_{ij}(t)} \left(X_i(t) - X_j(t)\right)$$
            \capt{где $R_{ij}(t) = \left\|X_i(t),\, X_j(t)\right\|_2$~--- евклидово расстояние.}
        Это правило является видоизмененным законом всемирного тяготения. Отличия заключаются, во-первых, в том, что множитель $R_{ij}(t)$ имеет степень $-1$, а не $-3$, а во-вторых, в том, что гравитационная постоянная $G$ введена как функция от времени. Первое изменение было выведено авторами экспериментально~--- так алгоритм быстрее сходился. Второе является следствием поисковой природы алгоритма~--- для нахождения точных решений необходимо повышать <<аккуратность>> алгоритма со временем, для чего необходимо уменьшать силы взаимодействия.
        \item С помощью независимых случайных величин ${rnd}_i \in [0, 1]$, вычисляется результирующая сила и ускорение:
            $$F_i(t) = \sum \limits_{j\in \mathrm{Kbest},\, j \ne i}^N {rnd}_j F_{ij}(t)$$
            \capt{где $\mathrm{Kbest} \subset \{1\dotsc n\}$~--- множество K лучших по оценке $f_i(t)$ агентов.}
            $$a_i(t) = \frac{F_i(t)}{M_i(t)}$$
        Это, соответственно, правило сложения сил, в которое добавили элемент случайности, и второй закон Ньютона.
        \item Производится перемещение агента:
            \begin{align*}
                V_i(t+1) &= {rnd}_i V_i(t) + a_i(t) \\
                X_i(t+1) &= X_i(t) + V_i(t+1) \\
                f_i(t+1) &= f(X_i(t+1))
            \end{align*}
            \capt{где ${rnd}_i$~--- независимые случайные величины на $[0,1]$.}
    \end{enumerate}
    \item Пересчитываются массы объектов:
        \begin{align*}
            w(t) &= \min_{i\in\{1\dotsc n]} f_i(t) \\
            b(t) &= \max_{i\in\{1\dotsc  n]} f_i(t) \\
            m_i(t) &= \frac{f_i(t) -  w(t)}{b(t)-w(t)} \\
            M_i(t+1) &= \frac{m_i(t)}{\sum_{j=1}^n m_j(t)}
        \end{align*}
    \item Шаг алгоритма повторяется определенное количество раз.
    \item Результат работы алгоритма~--- $X_i(t)$, где $i: \arg \max\limits_{i\in\{1\dotsc  n]} f_i(t)$.
\end{enumerate}

На основании вышеперечисленных алгоритмов можно составить представление об общих свойствах класса АКР. Большинство из них унаследованы от класса АЭМ, однако есть одно специфичное: на каждом шаге алгоритма каждому его агенту однозначно сопоставляется координата некоторого пространства. Т.о. мы можем говорить, что в АКР алгоритмах <<агенты располагаются в пространстве>>. Изменение сопоставленной агенту координаты на одной итерации алгоритма будем называть <<перемещением агента>>.

Очевидно, что вышеописанное свойство является достаточно важным с точки зрения программной реализации АКР, поскольку решение задач <<расположить в пространстве>> и <<переместить по пространству>> довольно трудоемко, особенно с учетом того, что пространство может быть бесконечным и обладать сложной топологией.

Существующие на данный момент системы поддержки АКР не учитывают этого свойства. Некоторые из них, например, JADE \cite{JADE} или MASS \cite{MASS} рассматривают агентов без привязки к определенному пространству. Большинство же рассчитаны на работу только в конечном двух- или трехмерном пространстве (таковы Repast \cite{Repast}, breve \cite{breve}). Кроме того, ни одна из известных систем не совместима с приложениями на платформе .NET \cite{DotNet4}.
