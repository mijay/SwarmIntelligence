\chapter{Теоретические основы}\label{sec:first}
\section{Понятия искусственного и вычислительного интеллекта}
Под искусственным интеллектом  понимается довольно обширный класс инструментов и технологий, границы которого во многом определяются историческими либо практическими причинами, а не общепринятыми формальными критериями, которых на данный момент не существует.

Наиболее распространенным подходом к определению интеллектуальности, а, следовательно, и ИИ \nomenclature{ИИ}{Искусственный Интеллект}, является агент-ориентированный подход, изложенный в одной из основополагающих работ в области --- \cite{Russel}. Ключевое понятие для этого подхода --- агент. Это некоторая сущность, которая способна воспринимать окружающую среду посредством датчиков и влиять на нее посредством исполнительных механизмов. Поведение агента считается интеллектуальным, если оно рационально в т.ч. и при меняющихся условиях среды. Эта модель требует наличия свойства адаптивности у алгоритмов ИИ.

Тем не менее, существуют другие подходы, например логический \cite{McCathy} или основанный на поиске \cite{NilsonNJ}, ярким примером которого является алгоритм A-star \cite{AStar}, который в настоящее время не относится к интеллектуальным.

В своей работе я исследовал лишь методы, относящиеся к области вычислительного интеллекта \cite{CompIntel}, интеллектуальность которых общепризнанна. Однако, также как и для интеллекта искусственного, для вычислительного не было построено четкого определения. Обширный обзор разработанных определений можно найти в \cite{CompIntelDef}. В этой-же работе автор приводит собственное, пожалуй, лучшее из представленных в литературе, хотя и излишне общее определение ВИ\nomenclature{ВИ}{Вычислительный Интеллект}: <<Вычислительный интеллект --- это область компьютерных наук, изучающая решение задач, для которых не существует эффективного алгоритмического решения>>.

Во многих работах, например \cite{MultTechDef}, ВИ определяется, как совокупность  различных технологий. Подобный остенсивный \cite{Ostensive} способ определения понятия обладает очевидными недостатками, поскольку не указывает на общие свойства этих технологий и не является расширяемым. В частности, в книге \cite{CompIntel} авторы относят к ВИ 4 типа алгоритмов, а 2 года спустя в \cite{MultTechDef} --- уже 7. Работы, использующие для определения ВИ именно такой --- остенсивный --- подход, обычно содержат довольно подробную классификацию существующих методов.

Согласно этим классификациям алгоритмы ВИ разбиваются на три подкласса: нейронные сети \cite{NS}, нечеткое управление \cite{FS} и эволюционное моделирование \cite{EM}.

\section{Алгоритмы эволюционного моделирования}
Перейдем к более подробному рассмотрению третьего класса алгоритмов --- алгоритмов эволюционного моделирования\nomenclature{АЭМ}{Алгоритмы Эволюционного Моделирования}. Эти алгоритмы предназначены для решения задач комбинаторной оптимизации.

Исторически, первыми представителями этого класса были генетические алгоритмы\nomenclature{ГА}{Генетические Алгоритмы}, предложенные Лоуренсом Фогелем в работе \cite{GA}. В их основу положен принцип моделирования генетической эволюции в смысле синтетической теории эволюции \cite{STE}. В самом общем виде генетический алгоритм формулируется следующим образом:

\begin{enumerate}
    \item Алгоритм оперирует особями --- некоторым представлением решений задачи. Каждая особь однозначно определяет допустимое решение. Для каждой особи определена ее функция приспособленности --- характеристика оптимальности решения ею определяемого.
    \item Алгоритм поддерживает пул особей, называемый популяцией, который характеризует его текущее состояние.
    \item При инициализации алгоритма некоторым образом создается начальная популяция.
    \item На каждом шаге алгоритма производятся три процесса:
    \begin{enumerate}
        \item Мутация: некоторым случайным образом выбираются несколько особей и для каждой из них в популяцию добавляется особь (или несколько особей), которая является ее некоторой случайной модификацией.
        \item Скрещивание: некоторым случайным (либо нет) образом выбираются пары особей. Для каждой из них некоторым случайным способом создаются и затем добавляются в популяцию некоторое количество производных особей.
        \item Отбор: из популяции удаляются особи имеющие плохую функцию приспособления либо слишком продолжительное время жизни (возможно сочетание критериев).
    \end{enumerate}
    \item Шаг алгоритма повторяется до тех пор пока не выполняться определенные условия. Например, пока в популяции не перестанут происходить существенные изменения.
    \item Результат работы алгоритма --- особь с лучшей функцией приспособленности.
\end{enumerate}

Для ГА известны способы доказательства корректности и сходимости алгоритмов \cite{ShodGA}, а также определения их эффективности \cite{OptGA}.

Другим АЭМ, зачастую противопоставляемым генетическим, является алгоритм Learnable Evolution Model \nomenclature{LEM}{Learnable Evolution Model}\cite{LEM}. Он также работает с представлением решений в виде особей с определенной функцией приспособленности и представлением текущего состояния в виде популяции. Однако в его основе лежит другая теория эволюции --- теория направленной эволюции (номогенез) \cite{Nomogen}. В самом общем виде алгоритм формулируется так:

\begin{enumerate}
    \item Некоторым способом создается начальная популяция.
    \item На каждом шаге алгоритма выполняются следующие действия:
    \begin{enumerate}
        \item Из популяции выделяются две группы особей: <<хорошие>> и <<плохие>> --- особи соответственно с высоким и низким значением функции приспособленности.
        \item С помощью методов машинного обучения строятся гипотезы --- описания отличительных черт <<хороших>> особей, которые не наблюдаются у <<плохих>>. Возможно также построение обратных гипотез --- черт присутствующих у <<плохих>>, но не у <<хороших>> особей.
        \item Генерируются новые особи, которые удовлетворяют гипотезам и не удовлетворяют обратным гипотезам.
        \item Эти особи тем или иным способом добавляются в популяцию. Например заменяя всех особей не являющихся <<хорошими>>.
    \end{enumerate}
    \item Шаг алгоритма повторяется до тех пор пока не выполняются определенные условия.
    \item Результат  работы алгоритма --- особь с лучшей функцией приспособленности.
\end{enumerate}

В качестве примера алгоритма АЭМ не оперирующего понятием <<эволюция>>, можно привести алгоритм Stochastic Diffusion Search \nomenclature{SDS}{Stochastic Diffusion Search} \cite{SDS}. Он, как и предыдущие алгоритмы, решает задачу поиска оптимального решения (элемента множества $S$) с точки зрения некоторой характеристики ($f: S\to\mathbb{R}$). В нем также вводится понятие особи, однако, в SDS особь не отождествляется с решением, а является независимым объектом, которому в каждый момент времени сопостовляют решение, т.о. может расссматриваться как частично определенная функция $a_i: T\to S$, $i\in\{1\dotsc n\}$. Алгоритм формулируется следующим образом:

\begin{enumerate}
    \item Некоторым способом особям сопоставляются начальные решения $a_i(0)$.
    \item На каждом шаге алгоритма выполняются следующие действия:
    \begin{enumerate}
        \item Для всех особей вычисляется качество их текущего решения: $f(a_i(t))$.
        \item Особи разделяются на две группы: <<хорошие>> и <<плохие>> --- особи соответственно с высоким и низким качеством решения.
        \item Для каждой <<плохой>> особи $i$:
        \begin{enumerate}
            \item Случайно выбирается особь $j\in\{1\dotsc n\}\setminus\{i\}$.
            \item Если особь $j$ <<хорошая>>, то $a_i(t+1)\gets a_j(t)$,
            \item иначе $a_i(t+1)\gets \mathrm{Rand}(S)$.
        \end{enumerate}
        \item Для всех <<хороших>> особей $a_i(t+1)\gets a_i(t)$.
    \end{enumerate}
    \item Шаг алгоритма повторяется до тех пор пока всем особям не будет сопоставленно малое число (или ровно одно) решений: $$\left\|\bigcup\limits_{i\in\{1\dotsc n\}} \{a_i(t)\}\right\|\to 1$$
    \item Результат работы алгоритма --- решение, которое сопоставленно наибольшему числу особей.
\end{enumerate}

Более подробный анализ SDS с доказательством некоторых его свойств, включая временную сложность $o(n)$, приведены в \cite{SDSTime}.
 
На основании вышеперечисленных алгоритмов можно выделить общие черты, присущие всем АЭМ:

\begin{enumerate}
    \item Алгоритм решает задачу оптимизации функции (называемой также функцией качества решения, функцией приспособленности) $f:S\to\mathbb{R}$, определенной на множестве значений (называемом также множеством решений) $S$. Чаще всего множество $S$ велико, а функция $f$ является трудно вычислимой.
    \item \label{EMcommon1} Состояние алгоритма представлено некоторым множеством (популяцией) некоторых объектов (особей) и, возможно, производными данными. Состояние алгоритма однозначно определяет набор решений --- выбранных значений из множества $S$.
    \item Алгоритм итеративный. Цель каждой итерации --- увеличить максимальное значение функции приспособленности для решений, определенных текущим сосотоянием. Фактически провести эволюцию популяции.
    \item Начальное состояние дается алгоритму извне --- обычно генерируется случайно.
    \item \label{EMcommon4} На каждой итерации алгоритм многократно (например для каждой особи, либо фиксированное число раз) выполняет некоторые действия.  Причем действия эти независимые и распараллеливаемые. В некоторых алгоритмах также выделяются стадии пред- и пост-процессинга.
    \item Алгоритм стохастический.
\end{enumerate}
    
Особо отметим, что вышеприведенные алгоритмы формируют более слабые ограничения для пунктов (\ref{EMcommon1}) и (\ref{EMcommon4}). Основываясь лишь на них, мы можем утчерждать, что во-первых <<Особь однозначно определяет одно решение>>, и во-вторых, <<На каждой итерации алгоритм выполняет некоторые действия для каждой особи>>. Однако существуют примеры АЭМ, которые не вписываются в эти, более узкие, рамки. Например, расширение пункта (\ref{EMcommon1}) необходимо для включения в класс АЭМ алгоритмов муравейника (англ. Ant Colony Optimisation) \cite{AntAlg} (решение в них кодируется не особью, а производными данными), а пункта (\ref{EMcommon4}) --- для включения алгоритма гармонического поиска \cite{HarmonySearch}.

Перечисленные свойства не являются определяющими для класса АЭМ, однако, они наблюдаются у всех общеизвестных алгоритмов.

Стоит заметить, что эти свойства являются весьма существенными с точки зрения программных реализаций алгоритмов. Они определяют задачи, которые должны быть решены в каждой из них. Это, в первую очередь, задачи создания удобной программной абстракции, выполнения сервисных операций с популяцией, распараллеливания и распределения по данным вычислений на каждой итерации. Их решение довольно трудоемко, что приводит к мысли о создании специализированных библиотек поддержки. Подобные библиотеки существуют (в качестве примера можно привести EO Evolutionary Computation Framework \cite{EOECF} и ECF \cite{ECF}), однако, ввиду чрезмерной общности данных свойств и их неестественности, такие библиотеки недостаточно удобны в использовании.

Неестественность общих свойств АЭМ во многом объясняется тем, что данный класс состоит из двух подклассов, представители которых существенно различны. Это подклассы алгоритмов эволюционных вычислений \cite{EvolComp} и коллективного разума \cite{SwarmIntel}. У каждого из них имеется гораздо больше общих свойств, и эти свойства гораздо естественнее, благодаря чему создание библиотеки поддержки становится более целесообразным.

В своей работе я сфокусировался на разработке подобной библиотеки для класса алгоритмов коллективного разума.

\section{Алгоритмы коллективного разума}
Исторически первым представителем класса алгоритмов коллективного разума \nomenclature{АКР}{Алгоритмы Коллективного Разума} (англ. Swarm Intelligence Algorithms) является алгоритм Particle Swarm Optimization \nomenclature{PSO}{Particle Swarm Optimization} \cite{PSO} опубликованый в 1942 г. Однако, непосредственно термин АКР а также ключевые свойства данного класса алгоритмов впервые были сформулированы только в 1989 г. в статье \cite{SwarmInRobotics}.

Основополагающей работой для всего класса класса АКР, во многом определившей его вид, считается \cite{AntAlg}. В ней описывается уже упоминавшийся ранее алгоритм муравейника для решения задачи коммивояжёра \cite{Barasin}. Позже, благодаря своей обобщенности, этот алгоритм был адаптирован для решения многих других задач, примеры которых можно найти в \cite{SwarmIntelDM}. Рассмотрим алгоритм муравейника в формулировке для решения задачи поиска кратчайшего пути на графе.

Алгоритм муравейника, как и другие представители класса АЭМ, оперирует популяцией особей (<<агентов>> в терминологии АКР; <<муравьев>> в терминологии данного алгоритма) и дополнительными данными: <<феромонами>> ($\tau_{i,j}(t)$), позволяющими ассоциировать с ребрами графа $G$ значения, указывающие на историю его использования муравьями. Ребрам графа также присвается некоторые внешние, с точки зрения алгоритма, значения --- <<веса>> ребер ($\eta_{i,j}(t)$). Алгоритм формулируется следующим образом:

\begin{enumerate}
    \item Некоторым способом изначально располагаем муравьев в вершинах графа. Полагаем $\forall (i, j) \in G: \tau_{i, j}(0) = 0$.
    \item На каждом шаге алгоритма для каждого муравья $\mathrm{ant}_k$, $k \in \{1\dotsc n\}$  расположенного  в вершине $i$ производятся следующие действия:
    \begin{enumerate}
        \item Вычисляется вероятность перехода муравья в каждую из допустимых вершин. Общая формула: $$ \forall  j \:|\: (i,j)\in G:\: p_{i,j}^k(t)=\frac{\left(\tau_{i,j}(t)\right)^\alpha \left(\eta_{i,j}(t)\right)^\beta} {\sum \limits_{l \in N} \left(\tau_{i,l}(t)\right)^\alpha \left(\eta_{i,l}(t)\right)^\beta} $$
        \item Выполняется случайный переход муравья по ребру $(i,\,j)$.
        \item Фиксированным для алгоритма способом определяется функция $\Delta\tau_{i,j}^k(t)$ и $\forall l \ne j \mbox{ полагаем } \Delta\tau_{i,l}^k(t) = 0$
    \end{enumerate}
    \item Для всех ребер осуществляется пересчет соответствующих феромонов: $$\tau_{i,j}(t+1) = \rho\tau_{i,j}(t) + \sum_{k=1}^n \Delta\tau_{i,j}^k(t),\,\mbox{где }0 \le \rho < 1$$
   \item Шаг алгоритма повторяется до тех пор пока в графе не образуется путь помеченный <<высоким уровнем>> феромонов: $\forall (i, j)\in\mathrm{Path}:\tau_{i, j}(t)\ge\Gamma$.
   \item Результат работы алгоритма --- путь помеченный высоким уровнем ферромонов.
\end{enumerate}

\todo{общие свойства АКР рассказать тут, заюзать то, что есть дальше}

\section{Многоагентные алгоритмы}

\todo{это вообще яростный бред}
Алгоритм муравейника является не только характерным примером АКР, но и другого, чрезвычайно похожего на первый взгляд, класса алгоритмов --- многоагентных алгоритмов\nomenclature{МАА}{Многоагентные Алгоритмы}. Границу между этими двумя классами не проводят в большей части литературы.

Дело в том, что МАА и АКР оба базируются на агентах, однако трактуют это понятие по разному. Как уже было указано выше, для АКР агент --- то же самое, что и особь для АЭМ, т.е. сущность, которой он оперирует и которая представляет решение. В то время как в МАА под агентом подразумевается агент в терминах агент-ориентированного подхода к ИИ \cite{Russel}, т.е. независимая, решающая задачу сущность, воспринимающая окружающую среду и взаимодействующая с ней.

Поскольку сам МАА также является агентом в этих терминах, то естественно, что необходимо вводить специальные ограничения, делающие задачи решаемые агентами разных уровней (МАА в целом $\longleftrightarrow$ агент в МАА) существенно различными. Типичным ограничением является  возможность работы лишь в подмножестве пространства исходной задачи.

Из определений очевидно, что МАА являются подмножеством АКР: с точностью до формулировок МАА являются АКР, в котором каждый агент решает задачу независимо от других (он может либо игнорировать другие  агенты, либо взаимодействовать с ними лишь опосредованно --- через сообщения или разделяемую память). Но это означает, что многоагентные системы, которые по сути являются МАА, естественно сводятся к терминам АКР. Этот факт с практической точки зрения представляет большой интерес.

К многоагентным системам относятся, в частности, эмуляции жизни, эволюции, социума и т.п., некоторые игры и многое другое. Все эти системы могут интерпретироваться как алгоритмы АКР и реализовываться поверх библиотеки их поддержки, что существенно расширяет область применимости такой библиотеки.

Примером АКР, которые не является МАА, может служить алгоритм гравитационного поиска (англ. Gravitational Search Algorithm \nomenclature{GSA}{Gravitational Search Algorithm}) \cite{GraviSearch}. Агенты в этом алгоритме обладают координатой $X_i(t)$ в пространстве решений, скоростью перемещения в этом пространстве --- $V_i(t)$ и массой --- $M_i(t)$. Для агента определена его оценка --- функция качества решения им определенного $f_i(t) = f(X_i(t))$. Алгоритм формулируется следующим образом:

\begin{enumerate}
    \item Некоторым способом агентам присваиваются начальные координаты $X_i(0)$.
    \item На каждом шаге алгоритма для каждого агента $i \in \{1\dotsc n\}$ выполняются следующие действия:
    \begin{enumerate}
        \item Вычислить силы взаимодействия с каждым другим агентом $j: j \ne i$ по формуле:
            $$F_{ij}(t) = G(t) \frac{M_i(t) M_j(t)}{R_{ij}(t)} \left(X_i(t) - X_j(t)\right)$$
            \capt{где $R_{ij}(t) = \left\|X_i(t),\, X_j(t)\right\|_2$ --- евклидово расстояние.}
        Это правило является видоизмененным законом всемирного тяготения. Отличия заключаются во-первых в том, что множитель $R_{ij}(t)$ имеет степень $-1$, а не $-3$, а во-вторых, в том что гравитационная постоянная $G$ введена как функция от времени. Первое изменение было выведено авторами экспериментально --- так алгоритм быстрее сходился. Второе является следствием поисковой природы алгоритма --- для нахождения точных решений необходимо повышать <<аккуратность>> алгоритма со временем, для чего необходимо уменьшить силы взаимодействия.
        \item С помощью независимых случайных величин ${rnd}_i \in [0, 1]$, вычисляются результирующая сила:
            $$F_i(t) = \sum \limits_{j\in \mathrm{Kbest},\, j \ne i}^N {rnd}_j F_{ij}(t)$$
            \capt{где $\mathrm{Kbest} \subset \{1\dotsc n\}$ --- множество K лучших по оценке $f_i(t-1)$ агентов.}
        $a_i(t) = F_i(t) \left/M_{ii}(t)\right.$. Это, соответственно, правило сложения сил, в которое добавили элемент случайности, и второй закон Ньютона.
        \item Производится перемещение объекта: \begin{align*} V_i(t+1) &= {rnd}_i V_i(t) + a_i(t) \\ X_i(t+1) &= X_i(t) + V_i(t+1) \end{align*} где ${rnd}_i$ --- независимые случайные величины на $[0,1]$. Затем пересчитывается его оценка $f_i(t+1) = f(X_i(t+1))$.
        \item Обновляются массы объектов:
        \begin{align*}
            w(t) &= \min_{i\in\{1\dotsc N]} f_i(t) \\
            b(t) &= \max_{i\in\{1\dotsc  N]} f_i(t) \\
            m_i(t) &= \frac{f_i(t) -  w(t)}{b(t)-w(t)} \\
            M_i(t+1) &= \frac{m_i(t)}{\sum_{j=1}^N m_j(t)}
        \end{align*}
    \end{enumerate}
\end{enumerate}

Тогда алгоритм каждой итерации следующий:


На примере трех вышеприведенных алгоритмов можно рассмотреть еще одну важную характеристику АКР --- тип пространства агентов. В части алгоритмов, в т.ч. в PSO и в GSA,  используются агенты располагаемые (обладающие координатой) в пространстве допустимых решений, в то время как в остальных алгоритмах (из приведенных --- в ACO) --- в пространстве задачи. Агенты первого типа являются агентами, оптимизирующими решения. Они аналогичны особям, используемым в ГА, LEM и других эволюционных алгоритмах \cite{EA}. Агенты второго типа являются агентами, строящими решение. Они могут быть использованы только в АКР и, более того, только в MAA. Большинство МАА (в т.ч. многоагентные системы) основаны на них. Однако, существуют исключения: упомянутые выше PSO, SDS и другие.

\section{Общие свойства АКР}\label{sec:akrprop}
Сформулируем общие свойства АКР:

\begin{enumerate}
    \item Алгоритм работает в некотором пространстве с координатами (карта).
    \item Работа алгоритма сводится к оперированию множеством (рой) сущностей (агентами) в этом пространстве.
    \item Состояние алгоритма определяется состоянием роя. Реже также используется память ассоциированная с точками пространства и/или небольшое количество глобальных переменных.
    \item Алгоритм итеративный. Одну итерацию будем называть ходом.
    \item \label{akrprop:indep} В течении хода алгоритм производит независимые действия над каждым агентом роя (обработка). Эти действия не образуют сторонних эффектов друг на друга: т.е. результат обработки для каждого агента не зависит от того, были ли обработаны другие агенты, в каком порядке они были обработаны, как они изменились и изменили хранимые данные в ходе обработки.
    \item Условие остановки алгоритмом не специфицируется.
    \item Начальное состояние данных и роя дается алгоритму извне. Координаты агентов в начальном рое обычно случайны (реже при их генерации используется эвристика).
    \item Алгоритм стохастический. Генерация случайных чисел (обычно многократная) необходима при обработке каждого агента.
\end{enumerate}
    
МАА в дополнение к вышеперечисленным также обладает следующими свойствами:

\begin{enumerate}
    \item Его агенты независимы. Результат обработки любого агента не зависит от состояния других агентов в любой момент времени. Взаимодействие агентов может быть лишь опосредованным, например, через совместный доступ к памяти.
    \item Агенты могут действовать лишь в своей ограниченной окрестности.
\end{enumerate}

АКР с оптимизирующими агентами обладает лишь одним специфичным свойством: карта является пространством допустимых решений, таким образом каждому агенту соответствует решение. Меру оптимальности (или отношение <<быть оптимальнее>>) определенную на решениях можно распространить на агентов и затем использовать для их сравнения.

В АКР со строящими агентами карта является пространством задачи. Таким образом каждый агент не является полноценным решением, а значит невозможно без введения эвристики производить их сравнение.
